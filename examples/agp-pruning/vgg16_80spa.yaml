#time python3 compress_classifier.py -a=vgg16 --pretrained -p=50 /home/cody/datasets/imagenet -j=30 --epochs=80 --lr=0.005 --compress=../agp-pruning/vgg16_80spa.yaml --vs=0 --resume-from ../../../vgg16_70spa_chkp/checkpoint.pth.tar

#time python3 compress_classifier.py -a=vgg16 --dataset=cifar10_resize -p=50 -b 16 ../../../data.cifar10/ -j=12 --epochs=50 --lr=0.005 --compress=../agp-pruning/vgg16_80spa.yaml --vs=0 --resume-from ./logs/vgg16_prune_after_70spa_cifar10___2019.10.22-093227/vgg16_prune_after_70spa_cifar10_checkpoint.pth.tar -n vgg16_prune_after_80spa_cifar10
version: 1

pruners:

  conv_pruner:
    class: AutomatedGradualPruner
    initial_sparsity : 0.70
    final_sparsity: 0.80
    weights: [
    #module.conv1.weight,
    features.module.0.weight,
    features.module.2.weight,
    features.module.5.weight,
    features.module.7.weight,
    features.module.10.weight,
    features.module.12.weight,
    features.module.14.weight,
    features.module.17.weight,
    features.module.19.weight,
    features.module.21.weight,
    features.module.24.weight,
    features.module.26.weight,
    features.module.28.weight,
    #classifier.0.weight,
    #classifier.3.weight]
    classifier.0.weight,
    classifier.3.weight,
    classifier.6.weight
    ]


lr_schedulers:
   pruning_lr:
     class: ExponentialLR
     gamma: 0.95


policies:

  - pruner:
      instance_name : conv_pruner
    starting_epoch: 0
    ending_epoch: 25
    frequency: 1


  - lr_scheduler:
      instance_name: pruning_lr
    starting_epoch: 26
    ending_epoch: 50
    frequency: 1